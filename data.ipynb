{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set();\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>muggy-smalt-axolotl-pembus</th>\n",
       "      <th>dorky-peach-sheepdog-ordinal</th>\n",
       "      <th>slimy-seashell-cassowary-goose</th>\n",
       "      <th>snazzy-harlequin-chicken-distraction</th>\n",
       "      <th>frumpy-smalt-mau-ordinal</th>\n",
       "      <th>stealthy-beige-pinscher-golden</th>\n",
       "      <th>chummy-cream-tarantula-entropy</th>\n",
       "      <th>hazy-emerald-cuttlefish-unsorted</th>\n",
       "      <th>nerdy-indigo-wolfhound-sorted</th>\n",
       "      <th>leaky-amaranth-lizard-sorted</th>\n",
       "      <th>...</th>\n",
       "      <th>wheezy-myrtle-mandrill-entropy</th>\n",
       "      <th>wiggy-lilac-lemming-sorted</th>\n",
       "      <th>gloppy-cerise-snail-contributor</th>\n",
       "      <th>woozy-silver-havanese-gaussian</th>\n",
       "      <th>jumpy-thistle-discus-sorted</th>\n",
       "      <th>muggy-turquoise-donkey-important</th>\n",
       "      <th>blurry-buff-hyena-entropy</th>\n",
       "      <th>bluesy-chocolate-kudu-fepid</th>\n",
       "      <th>gamy-white-monster-expert</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.070654</td>\n",
       "      <td>1.018160</td>\n",
       "      <td>0.228643</td>\n",
       "      <td>0.857221</td>\n",
       "      <td>0.052271</td>\n",
       "      <td>0.230303</td>\n",
       "      <td>-6.385090</td>\n",
       "      <td>0.439369</td>\n",
       "      <td>-0.721946</td>\n",
       "      <td>-0.227027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351895</td>\n",
       "      <td>0.618824</td>\n",
       "      <td>-1.542423</td>\n",
       "      <td>0.598175</td>\n",
       "      <td>0.611757</td>\n",
       "      <td>0.678772</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>-0.806677</td>\n",
       "      <td>-0.193649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.491702</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>1.071266</td>\n",
       "      <td>-0.346347</td>\n",
       "      <td>-0.082209</td>\n",
       "      <td>0.110579</td>\n",
       "      <td>-0.382374</td>\n",
       "      <td>-0.229620</td>\n",
       "      <td>0.783980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645115</td>\n",
       "      <td>-1.246090</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>-0.479664</td>\n",
       "      <td>1.581289</td>\n",
       "      <td>0.931258</td>\n",
       "      <td>0.151937</td>\n",
       "      <td>-0.766595</td>\n",
       "      <td>0.474351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.680473</td>\n",
       "      <td>0.860529</td>\n",
       "      <td>-1.076195</td>\n",
       "      <td>0.740124</td>\n",
       "      <td>3.678445</td>\n",
       "      <td>0.288558</td>\n",
       "      <td>0.515875</td>\n",
       "      <td>0.920590</td>\n",
       "      <td>-1.223277</td>\n",
       "      <td>-1.029780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516422</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>-0.459210</td>\n",
       "      <td>2.028205</td>\n",
       "      <td>-0.093968</td>\n",
       "      <td>-0.218274</td>\n",
       "      <td>-0.163136</td>\n",
       "      <td>-0.870289</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183774</td>\n",
       "      <td>0.919134</td>\n",
       "      <td>-0.946958</td>\n",
       "      <td>0.918492</td>\n",
       "      <td>0.862278</td>\n",
       "      <td>1.155287</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>-1.349685</td>\n",
       "      <td>-1.182729</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.168967</td>\n",
       "      <td>1.385089</td>\n",
       "      <td>-0.353028</td>\n",
       "      <td>3.316150</td>\n",
       "      <td>-0.524087</td>\n",
       "      <td>-0.794327</td>\n",
       "      <td>3.936365</td>\n",
       "      <td>0.682989</td>\n",
       "      <td>-2.521211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.203933</td>\n",
       "      <td>-0.177252</td>\n",
       "      <td>0.368074</td>\n",
       "      <td>-0.701320</td>\n",
       "      <td>-1.104391</td>\n",
       "      <td>0.735760</td>\n",
       "      <td>0.894273</td>\n",
       "      <td>-1.375826</td>\n",
       "      <td>-5.144946</td>\n",
       "      <td>-2.048711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279168</td>\n",
       "      <td>1.544356</td>\n",
       "      <td>2.959727</td>\n",
       "      <td>1.641201</td>\n",
       "      <td>-0.130818</td>\n",
       "      <td>-0.264292</td>\n",
       "      <td>-0.748668</td>\n",
       "      <td>0.964218</td>\n",
       "      <td>0.087079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   muggy-smalt-axolotl-pembus  dorky-peach-sheepdog-ordinal  \\\n",
       "0                   -2.070654                      1.018160   \n",
       "1                   -0.491702                      0.082645   \n",
       "2                   -1.680473                      0.860529   \n",
       "3                    0.183774                      0.919134   \n",
       "4                   -0.203933                     -0.177252   \n",
       "\n",
       "   slimy-seashell-cassowary-goose  snazzy-harlequin-chicken-distraction  \\\n",
       "0                        0.228643                              0.857221   \n",
       "1                       -0.011193                              1.071266   \n",
       "2                       -1.076195                              0.740124   \n",
       "3                       -0.946958                              0.918492   \n",
       "4                        0.368074                             -0.701320   \n",
       "\n",
       "   frumpy-smalt-mau-ordinal  stealthy-beige-pinscher-golden  \\\n",
       "0                  0.052271                        0.230303   \n",
       "1                 -0.346347                       -0.082209   \n",
       "2                  3.678445                        0.288558   \n",
       "3                  0.862278                        1.155287   \n",
       "4                 -1.104391                        0.735760   \n",
       "\n",
       "   chummy-cream-tarantula-entropy  hazy-emerald-cuttlefish-unsorted  \\\n",
       "0                       -6.385090                          0.439369   \n",
       "1                        0.110579                         -0.382374   \n",
       "2                        0.515875                          0.920590   \n",
       "3                        0.911106                          0.562598   \n",
       "4                        0.894273                         -1.375826   \n",
       "\n",
       "   nerdy-indigo-wolfhound-sorted  leaky-amaranth-lizard-sorted   ...    \\\n",
       "0                      -0.721946                     -0.227027   ...     \n",
       "1                      -0.229620                      0.783980   ...     \n",
       "2                      -1.223277                     -1.029780   ...     \n",
       "3                      -1.349685                     -1.182729   ...     \n",
       "4                      -5.144946                     -2.048711   ...     \n",
       "\n",
       "   wheezy-myrtle-mandrill-entropy  wiggy-lilac-lemming-sorted  \\\n",
       "0                        0.351895                    0.618824   \n",
       "1                       -0.645115                   -1.246090   \n",
       "2                        0.516422                    0.130521   \n",
       "3                       -1.168967                    1.385089   \n",
       "4                       -0.279168                    1.544356   \n",
       "\n",
       "   gloppy-cerise-snail-contributor  woozy-silver-havanese-gaussian  \\\n",
       "0                        -1.542423                        0.598175   \n",
       "1                         2.613357                       -0.479664   \n",
       "2                        -0.459210                        2.028205   \n",
       "3                        -0.353028                        3.316150   \n",
       "4                         2.959727                        1.641201   \n",
       "\n",
       "   jumpy-thistle-discus-sorted  muggy-turquoise-donkey-important  \\\n",
       "0                     0.611757                          0.678772   \n",
       "1                     1.581289                          0.931258   \n",
       "2                    -0.093968                         -0.218274   \n",
       "3                    -0.524087                         -0.794327   \n",
       "4                    -0.130818                         -0.264292   \n",
       "\n",
       "   blurry-buff-hyena-entropy  bluesy-chocolate-kudu-fepid  \\\n",
       "0                   0.247059                    -0.806677   \n",
       "1                   0.151937                    -0.766595   \n",
       "2                  -0.163136                    -0.870289   \n",
       "3                   3.936365                     0.682989   \n",
       "4                  -0.748668                     0.964218   \n",
       "\n",
       "   gamy-white-monster-expert  target  \n",
       "0                  -0.193649       0  \n",
       "1                   0.474351       0  \n",
       "2                   0.064038       1  \n",
       "3                  -2.521211       0  \n",
       "4                   0.087079       0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262144, 257)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royluo/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/royluo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "/Users/royluo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.target\n",
    "X = df.iloc[:,0:-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "nb = GaussianNB()\n",
    "#multi_nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "#multi_nb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.52      0.51      0.51     26428\\n           1       0.51      0.52      0.51     26001\\n\\n   micro avg       0.51      0.51      0.51     52429\\n   macro avg       0.51      0.51      0.51     52429\\nweighted avg       0.51      0.51      0.51     52429\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = nb.predict(X_test)\n",
    "\n",
    "classification_report(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5119327543647874"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc = roc_auc_score\n",
    "roc(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:19:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:19:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:19:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:19:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:19:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:19:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:20:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[15:20:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=False, subsample=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "gbm = xgb.XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=10, silent=False, objective='binary:logistic')\n",
    "gbm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108143211882852"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_pred = gbm.predict(X_test)\n",
    "roc(gbm_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
